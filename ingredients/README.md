# ü•ò Ingredient Detection Pipeline

–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ –¥–µ—Ç–µ–∫—Ü—ñ—è —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç—ñ–≤ –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö —ó–∂—ñ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é DenseNet121 CNN –º–æ–¥–µ–ª—ñ.

## üìã –û–≥–ª—è–¥

–¶–µ–π –º–æ–¥—É–ª—å —Ä–æ–∑–ø—ñ–∑–Ω–∞—î **154 —Ä—ñ–∑–Ω–∏—Ö —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç–∏** –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö —ó–∂—ñ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ –º—É–ª—å—Ç–∏–ª–µ–π–±–ª –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—é. –ú–æ–¥–µ–ª—å –Ω–∞–≤—á–µ–Ω–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç—ñ Food-101/Food-256 –∑ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—é –¥–æ —Ä–µ—Ü–µ–ø—Ç—ñ–≤ —Ç–∞ —ó—Ö —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç—ñ–≤.

## üèÜ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏

**Top-30 —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç—ñ–≤ (–∑–∞ F1-score):**

| –†–∞–Ω–≥ | –Ü–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç | Precision | Recall | F1-Score |
|------|-----------|-----------|--------|----------|
| 1 | mascarpone | 0.923 | 0.750 | 0.827 |
| 2 | coconut oil | 0.947 | 0.581 | 0.720 |
| 3 | coffee | 0.640 | 0.800 | 0.711 |
| 4 | croutons | 0.769 | 0.625 | 0.690 |
| 5 | lamb | 0.600 | 0.733 | 0.660 |
| ... | ... | ... | ... | ... |
| 30 | breadcrumbs | 0.420 | 0.631 | 0.504 |

**–ü–æ–≤–Ω–∏–π –Ω–∞–±—ñ—Ä –º–µ—Ç—Ä–∏–∫:** –¥–∏–≤. `data/top_30_metrics.csv`

## üîß –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª—ñ

```python
DenseNet121 (ImageNet pre-trained)
‚îú‚îÄ‚îÄ Conv Features (ImageNet weights)
‚îú‚îÄ‚îÄ Adaptive Pool
‚îî‚îÄ‚îÄ Classifier
    ‚îú‚îÄ‚îÄ Dropout(0.5)
    ‚îî‚îÄ‚îÄ Linear(1024 ‚Üí 154)  # Multi-label outputs
```

- **–ë–∞–∑–æ–≤–∞ –º–æ–¥–µ–ª—å**: DenseNet121 –∑ ImageNet weights
- **–í–∏—Ö—ñ–¥–Ω—ñ –∫–ª–∞—Å–∏**: 154 —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç–∏
- **–ê–∫—Ç–∏–≤–∞—Ü—ñ—è**: Sigmoid (–¥–ª—è Multi-label)
- **–ü–æ—Ä–æ–≥ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è**: 0.5

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞

```
ingredients/
‚îú‚îÄ‚îÄ README.md                              # –¶–µ–π —Ñ–∞–π–ª
‚îú‚îÄ‚îÄ REPRODUCTION_GUIDE.md                  # –ü–æ–≤–Ω–∏–π –≥–∞–π–¥ –¥–ª—è –≤—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ best_ingredient_model_f1_0.4975.pth    # –ù–∞–≤—á–µ–Ω–∞ –º–æ–¥–µ–ª—å
‚îÇ   ‚îî‚îÄ‚îÄ ingredient_vocabulary_V4_FINAL.json    # –°–ª–æ–≤–Ω–∏–∫ (154 —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç–∏)
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ pytorch_gpu_universal_script.py         # –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
‚îÇ   ‚îú‚îÄ‚îÄ eval_per_class_grouped.py               # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è Top-30 –º–µ—Ç—Ä–∏–∫
‚îÇ   ‚îî‚îÄ‚îÄ run_pipeline_real.py                    # –ü–æ–≤–Ω–∞ evaluation pipeline
‚îî‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ top_30_metrics.csv                      # Top-30 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
    ‚îú‚îÄ‚îÄ recipes_dataset_en_cleaned.json         # –î–∞—Ç–∞—Å–µ—Ç —Ä–µ—Ü–µ–ø—Ç—ñ–≤ (34 MB)
    ‚îî‚îÄ‚îÄ image_to_recipe_assignments_f4_its.json # –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è‚Üî–†–µ—Ü–µ–ø—Ç–∏ (22 MB)
```

## üöÄ –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç

### 1Ô∏è‚É£ –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π

```bash
pip install torch torchvision scikit-learn pandas numpy tqdm
```

### 2Ô∏è‚É£ –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å —Ç–∞ —Å–ª–æ–≤–Ω–∏–∫

–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ —Ñ–∞–π–ª–∏ –∑ –ø–∞–ø–∫–∏ `models/`:
- `best_ingredient_model_f1_0.4975.pth` - –º–æ–¥–µ–ª—å (29 MB)
- `ingredient_vocabulary_V4_FINAL.json` - —Å–ª–æ–≤–Ω–∏–∫ —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç—ñ–≤

### 3Ô∏è‚É£ –ó—Ä–æ–±–∏—Ç–∏ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ

```python
import torch
from torchvision import transforms, models
import json
from PIL import Image

# –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å
model = models.densenet121()
model.classifier = torch.nn.Linear(1024, 154)
model.load_state_dict(torch.load('models/best_ingredient_model_f1_0.4975.pth'))
model.eval()

# –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å–ª–æ–≤–Ω–∏–∫
with open('models/ingredient_vocabulary_V4_FINAL.json') as f:
    ing_to_idx = json.load(f)
    vocab = [None] * len(ing_to_idx)
    for ing, idx in ing_to_idx.items():
        vocab[idx] = ing

# –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
image = Image.open('food_image.jpg').convert('RGB')
with torch.no_grad():
    output = model(transform(image).unsqueeze(0))
    probs = torch.sigmoid(output).squeeze(0).numpy()

# –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ (–ø–æ—Ä–æ–≥ 0.5)
detected = [(vocab[i], float(p)) for i, p in enumerate(probs) if p > 0.5]
detected.sort(key=lambda x: x[1], reverse=True)
print(detected)
```

## üìä –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ

–î–∏–≤. `REPRODUCTION_GUIDE.md` –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –≥–∞–π–¥—É.

### –®–≤–∏–¥–∫–∏–π –∑–∞–ø—É—Å–∫:

```bash
cd scripts
python pytorch_gpu_universal_script.py
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä–∏:**
- `BATCH_SIZE = 32`
- `EPOCHS = 50`
- `LEARNING_RATE = 1e-4`
- `MIN_INGREDIENT_FREQUENCY = 20`

## üìà Evaluation

### –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è Top-30 –º–µ—Ç—Ä–∏–∫:

```bash
cd scripts
python eval_per_class_grouped.py
```

–†–µ–∑—É–ª—å—Ç–∞—Ç: `top_30_metrics.csv` + `top_30_ingredients_grouped.png`

### –ü–æ–≤–Ω–∞ evaluation pipeline:

```bash
cd scripts
python run_pipeline_real.py
```

–ü–æ—Ç—Ä–µ–±—É—î:
- Ollama –∑ –º–æ–¥–µ–ª–ª—é `llama3.1`
- –ì–µ–Ω–µ—Ä—É—î –¥–µ—Ç–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ BLEU, ROUGE, Cosine Similarity

## üì¶ –í—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è

**–¢—Ä–∏ –æ–±–æ–≤'—è–∑–∫–æ–≤—ñ JSON —Ñ–∞–π–ª–∏:**

1. **recipes_dataset_en_cleaned.json** (34 MB)
   - –°—Ç—Ä—É–∫—Ç—É—Ä–∞: `{ recipe_name: { ingredients: [...], instructions: "...", ... }, ... }`
   - 11k+ —Ä–µ—Ü–µ–ø—Ç—ñ–≤ –¥–ª—è Food-256 –∫–∞—Ç–µ–≥–æ—Ä—ñ–π

2. **image_to_recipe_assignments_f4_its.json** (22 MB)
   - –°—Ç—Ä—É–∫—Ç—É—Ä–∞: `{ image_path: category, ... }`
   - –í—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π —Ä–µ—Ü–µ–ø—Ç—ñ–≤

3. **–î–∞—Ç–∞—Å–µ—Ç –∑–æ–±—Ä–∞–∂–µ–Ω—å** (Food-256)
   - –°—Ç—Ä—É–∫—Ç—É—Ä–∞: `dataset_256/dataset/images/{category}/{image}.jpg`
   - 256 –∫–∞—Ç–µ–≥–æ—Ä—ñ–π, ~150k –∑–æ–±—Ä–∞–∂–µ–Ω—å

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Å—Ç–≤–æ—Ä—é—î—Ç—å—Å—è –ø—ñ–¥ —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è:**
- `ingredient_vocabulary_V4_FINAL.json` - —Å–ª–æ–≤–Ω–∏–∫ –∑ 154 —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç—ñ–≤

## üîç –ü–∞—Ä—Å–∏–Ω–≥ —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç—ñ–≤

–Ü–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç–∏ –ø—Ä–æ—Ö–æ–¥—è—Ç—å –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—é —Ç–∞ –∫–æ–Ω—Å–æ–ª—ñ–¥–∞—Ü—ñ—é:

```
"olive oil" ‚Üí "oil"
"granulated sugar" ‚Üí "sugar"
"chicken breast" ‚Üí "chicken"
```

- –í–∏–¥–∞–ª—è—é—Ç—å—Å—è —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ —Ç–∞ –æ–¥–∏–Ω–∏—Ü—ñ –≤–∏–º—ñ—Ä—É
- –ú—ñ–Ω—ñ–º—É–º 20 –∑–æ–±—Ä–∞–∂–µ–Ω—å –Ω–∞ —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç –¥–ª—è –≤–∫–ª—é—á–µ–Ω–Ω—è —É –Ω–∞–≤—á–∞–Ω–Ω—è
- 154 –æ—Å—Ç–∞—Ç–æ—á–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤

## ‚ö†Ô∏è –í–∞–∂–ª–∏–≤—ñ –º–æ–º–µ–Ω—Ç–∏

1. **–ü–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤–Ω–∏–∫–∞ –∫—Ä–∏—Ç–∏—á–Ω–∏–π** ‚Äî —ñ–Ω–¥–µ–∫—Å –º–∞—î –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—Ç–∏ –Ω–µ–π—Ä–æ–Ω–∞–º –≤–∏—Ö—ñ–¥–Ω–æ–≥–æ —à–∞—Ä—É
2. **–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —à–ª—è—Ö—ñ–≤** ‚Äî —Å–∫—Ä–∏–ø—Ç–∏ –æ—á—ñ–∫—É—é—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ `../dataset_256/`
3. **GPU —Ä–µ–∫–æ–º–µ–Ω–¥—É—î—Ç—å—Å—è** ‚Äî –Ω–∞–≤—á–∞–Ω–Ω—è –Ω–∞ CPU –±—É–¥–µ –ø–æ–≤—ñ–ª—å–Ω–∏–º
4. **–ú—É–ª—å—Ç–∏–ª–µ–π–±–ª –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è** ‚Äî –æ–¥–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –º–æ–∂–µ –º—ñ—Å—Ç–∏—Ç–∏ –±–∞–≥–∞—Ç–æ —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç—ñ–≤

## üß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è

### –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –¥–∞–Ω—ñ:

```bash
python -c "import json; v=json.load(open('models/ingredient_vocabulary_V4_FINAL.json')); print(f'Vocabulary: {len(v)} ingredients')"
python -c "import json; r=json.load(open('data/recipes_dataset_en_cleaned.json')); print(f'Recipes: {len(r)}')"
```

### –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –º–æ–¥–µ–ª—å:

```bash
python -c "import torch; m=torch.load('models/best_ingredient_model_f1_0.4975.pth'); print(f'Model size: {sum(p.numel() for p in m.values())} params')"
```

## üìö –ü–æ—Å–∏–ª–∞–Ω–Ω—è

- [DenseNet Paper](https://arxiv.org/abs/1608.06993)
- [Food-101 Dataset](https://www.tensorflow.org/datasets/catalog/food101)
- [PyTorch Vision Models](https://pytorch.org/vision/stable/models.html)

## üìù –õ—ñ—Ü–µ–Ω–∑—ñ—è

–î–∏–≤. –æ—Å–Ω–æ–≤–Ω–∏–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ–π

---

**–Ü–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç–Ω–∞ –¥–µ—Ç–µ–∫—Ü—ñ—è | DenseNet121 | 154 –∫–ª–∞—Å–∏ | 2025**
